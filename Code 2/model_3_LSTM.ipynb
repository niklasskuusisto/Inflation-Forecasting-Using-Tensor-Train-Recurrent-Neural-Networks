{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"q1k0j6BMmJzp","outputId":"460c3210-0bb6-4d0f-af64-7c98974e6d76","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694346241978,"user_tz":-60,"elapsed":3184,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"]}],"source":["%reset"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"5_JzbLTamJzq","executionInfo":{"status":"ok","timestamp":1694346241978,"user_tz":-60,"elapsed":8,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"outputs":[],"source":["#!pip uninstall keras-nightly"]},{"cell_type":"code","execution_count":3,"metadata":{"tags":[],"id":"h4MRLutUmJzq","executionInfo":{"status":"ok","timestamp":1694346241979,"user_tz":-60,"elapsed":7,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"outputs":[],"source":["#!pip install tensorflow\n","#!pip install keras==2.12.*"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive') # Outputs will be saved in your google drive"],"metadata":{"id":"PY_qzn2bm5Qo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694346271988,"user_tz":-60,"elapsed":30015,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}},"outputId":"e381e101-8df5-4381-b6b9-3aa8b93210f3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"UI08d2r_mJzr","executionInfo":{"status":"ok","timestamp":1694346273727,"user_tz":-60,"elapsed":1746,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","\n","import statsmodels\n","import statsmodels.tsa.api as sm\n","from statsmodels.tsa.api import VAR\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import GridSearchCV\n","\n","import matplotlib.dates as mdates\n","\n","from datetime import datetime\n","from sklearn import preprocessing"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"dhjcfDYRmJzr","executionInfo":{"status":"ok","timestamp":1694346277773,"user_tz":-60,"elapsed":4050,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras as keras\n","\n","from keras.callbacks import EarlyStopping\n","from keras import backend as K\n","from keras.layers import Layer\n","from keras import activations\n","from keras import initializers\n","from keras.layers import Dense, LSTM, SimpleRNN, Flatten\n","\n","from keras.models import Sequential\n","#from tensorflow.keras.optimizers import SGD\n","#from keras.utils.np_utils import to_categorical\n","\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"4-JZ0nlsmJzr","executionInfo":{"status":"ok","timestamp":1694346280691,"user_tz":-60,"elapsed":2921,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"outputs":[],"source":["# not sure which random seeds are relevant below (just in case included them all)\n","#keras.utils.set_random_seed(42)\n","#np.random.seed(42)\n","#tf.random.set_seed(42)\n","\n","tf.get_logger().setLevel('INFO')"]},{"cell_type":"code","source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yE88PxIWuoZA","executionInfo":{"status":"ok","timestamp":1694346280923,"user_tz":-60,"elapsed":4,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}},"outputId":"d77094c6-0f94-4e05-9ab4-4194daafb905"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"markdown","source":["The loss function is used to optimize your model. This is the function that will get minimized by the optimizer.\n","\n","A metric is used to judge the performance of your model. This is only for you to look at and has nothing to do with the optimization process."],"metadata":{"id":"DBGQHu00wPig"}},{"cell_type":"code","source":["input_path_original = '/content/drive/MyDrive/Colab Notebooks/Gradu/Data/Original inflation/' # this contains original inflation values that are needed for reversin the stationarity transformation later\n","input_path = '/content/drive/MyDrive/Colab Notebooks/Gradu/Data/Features added/'"],"metadata":{"id":"FF-Kl31fwQ4f","executionInfo":{"status":"ok","timestamp":1694346280923,"user_tz":-60,"elapsed":3,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["countries = ['Finland', 'United States', 'Germany', 'France', 'Spain', 'Italy', 'Netherlands', 'Sweden', 'Belgium', 'Denmark', 'Austria', 'Poland']\n","#countries = ['Finland']\n","transformations = ['FD', 'FD', 'none', 'FD', 'FD', 'FD', 'FD', 'none', 'none', 'FD', 'none', 'FD']\n","#transformations = ['FD']"],"metadata":{"id":"pRK0BzTcwQ9w","executionInfo":{"status":"ok","timestamp":1694346280923,"user_tz":-60,"elapsed":3,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["macro_variables = ['inflation', 'unemployment', 'imports', 'exports', 'bond_yield', 'exchange', 'ppi', 'bci', 'cci', 'construction', 'manufacturing', 'share_prices', 'gdp', 'house_prices', 'investment', 'domestic_demand']\n","common_variables = ['oil', 'silver', 'eurusd', 'eurcfh', 'spx', 'world']\n","\n","all_variables = macro_variables + common_variables"],"metadata":{"id":"h8uoD3kuwRWq","executionInfo":{"status":"ok","timestamp":1694346280923,"user_tz":-60,"elapsed":3,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def get_data(variable, path_in = input_path):\n","    input_file = path_in + variable +'.csv'\n","    data = pd.read_csv(input_file, header=0, index_col=0)\n","    data.index = pd.to_datetime(data.index)\n","    data = data.astype(float)\n","    data = data.sort_index()\n","    return data"],"metadata":{"id":"WNT4AJi0wRY6","executionInfo":{"status":"ok","timestamp":1694346280923,"user_tz":-60,"elapsed":3,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# drop constant columns\n","\n","def drop_constant_columns(data):\n","    non_constant_columns = data.columns[data.nunique() > 1]  # Find non-constant columns\n","    return data[non_constant_columns].copy()  # Return new DataFrame with non-constant columns"],"metadata":{"id":"oVSkbr53wRbT","executionInfo":{"status":"ok","timestamp":1694346280923,"user_tz":-60,"elapsed":2,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# create the matrix of variables\n","\n","# initialise dataframe with hicp_Finland data after which more columns are added into it\n","init_index = get_data(\"inflation_Finland\", input_path)\n","df = pd.DataFrame(index = init_index.index)\n","\n","for variable in macro_variables:\n","    for country in countries:\n","        data = get_data(variable + \"_\" + country)\n","        new_column_name = variable + \"_\" + country\n","        data = data.rename({'Data': new_column_name}, axis=1)\n","        df[new_column_name] = data\n","\n","for variable in common_variables:\n","    data = get_data(variable + \"_\" + 'Finland')\n","    new_column_name = variable + \"_\" + 'common'\n","    data = data.rename({'Data': new_column_name}, axis=1)\n","    df[new_column_name] = data\n","#df = df.replace(np.inf, np.nan).replace(-np.inf, np.nan).dropna()\n","\n","df = drop_constant_columns(df)\n","print(df.shape)\n","print(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aMPlCZSEwRdW","executionInfo":{"status":"ok","timestamp":1694346324961,"user_tz":-60,"elapsed":44041,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}},"outputId":"73374f07-9656-498c-bd22-699dc68c8872"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n","<ipython-input-14-b86d5496bf3f>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n"]},{"output_type":"stream","name":"stdout","text":["(276, 196)\n","            inflation_Finland  inflation_United States  inflation_Germany  \\\n","Date                                                                        \n","2000-01-01           0.025006                 0.013511            1.54946   \n","2000-02-01           0.512560                 0.482990            1.54762   \n","2000-03-01           0.364720                 0.535700            1.54762   \n","2000-04-01          -0.503340                -0.688990            1.06635   \n","2000-05-01           0.053520                 0.120340            0.94787   \n","...                       ...                      ...                ...   \n","2022-08-01          -0.169370                -0.262130            6.95652   \n","2022-09-01           0.503220                -0.061020            8.57418   \n","2022-10-01           0.191470                -0.456240            8.82071   \n","2022-11-01           0.827470                -0.635110            8.80383   \n","2022-12-01           0.006800                -0.655920            8.11843   \n","\n","            inflation_France  inflation_Spain  inflation_Italy  \\\n","Date                                                             \n","2000-01-01          0.015679         0.010289         0.034285   \n","2000-02-01         -0.183720         0.084580         0.179280   \n","2000-03-01          0.135690        -0.045620         0.087130   \n","2000-04-01         -0.283750         0.047100        -0.189250   \n","2000-05-01          0.190440         0.174420         0.178000   \n","...                      ...              ...              ...   \n","2022-08-01         -0.167700        -0.221140         0.445570   \n","2022-09-01         -0.361210        -1.677120         0.492610   \n","2022-10-01          0.648550        -1.607160         2.971530   \n","2022-11-01         -0.050340        -0.455270        -0.066880   \n","2022-12-01         -0.299410        -1.101870        -0.137970   \n","\n","            inflation_Netherlands  inflation_Sweden  inflation_Belgium  \\\n","Date                                                                     \n","2000-01-01               0.028318           0.44805            1.77596   \n","2000-02-01               0.115030           0.93123            1.93566   \n","2000-03-01               0.024490           1.03253            2.24734   \n","2000-04-01              -0.058720           0.72040            2.04885   \n","2000-05-01               0.299130           1.00897            2.16714   \n","...                           ...               ...                ...   \n","2022-08-01               1.671590           9.83168            9.94416   \n","2022-09-01               2.572830          10.83762           11.27499   \n","2022-10-01              -0.206810          10.85325           12.26795   \n","2022-11-01              -4.446250          11.46453           10.62873   \n","2022-12-01              -0.292060          12.33864           10.35079   \n","\n","            inflation_Denmark  ...  domestic_demand_Sweden  \\\n","Date                           ...                           \n","2000-01-01           0.020236  ...                2.240000   \n","2000-02-01          -0.159240  ...                6.817574   \n","2000-03-01           0.238580  ...                9.248259   \n","2000-04-01          -0.188690  ...                9.787459   \n","2000-05-01           0.218690  ...                8.690578   \n","...                       ...  ...                     ...   \n","2022-08-01           0.206070  ...                1.103995   \n","2022-09-01           1.108950  ...               -2.743656   \n","2022-10-01           0.093460  ...               -6.014211   \n","2022-11-01          -1.242150  ...               -7.261663   \n","2022-12-01          -0.146010  ...               -5.040000   \n","\n","            domestic_demand_Belgium  domestic_demand_Denmark  \\\n","Date                                                           \n","2000-01-01                 4.010000                 0.015418   \n","2000-02-01                 3.860278                 2.006396   \n","2000-03-01                 3.955180                -1.707898   \n","2000-04-01                 4.203509                -3.813225   \n","2000-05-01                 4.514068                -4.309586   \n","...                             ...                      ...   \n","2022-08-01                 2.903722                -9.444820   \n","2022-09-01                 2.774335                -9.864710   \n","2022-10-01                 2.357547                -4.789016   \n","2022-11-01                 1.580417                 5.782264   \n","2022-12-01                 0.370000                21.849128   \n","\n","            domestic_demand_Austria  oil_common  silver_common  eurusd_common  \\\n","Date                                                                            \n","2000-01-01                 1.190000    0.004350       0.005484       0.000359   \n","2000-02-01                 3.362871    0.078472      -0.040853      -0.004963   \n","2000-03-01                 3.644453   -0.125780      -0.009046      -0.008850   \n","2000-04-01                 2.785984   -0.036173      -0.009328      -0.046998   \n","2000-05-01                 1.538702    0.169755      -0.005599       0.027674   \n","...                             ...         ...            ...            ...   \n","2022-08-01                -2.443356   -0.083511      -0.126059      -0.015882   \n","2022-09-01                -2.587548   -0.116294       0.064542      -0.025989   \n","2022-10-01                -2.232877    0.107789       0.004193       0.008536   \n","2022-11-01                -1.450107   -0.104388       0.130355       0.051470   \n","2022-12-01                -0.310000    0.005603       0.098681       0.028144   \n","\n","            eurcfh_common  spx_common  world_common  \n","Date                                                 \n","2000-01-01      -0.001762    0.003683      0.002638  \n","2000-02-01      -0.000187   -0.020313      0.018634  \n","2000-03-01      -0.008882    0.092324      0.001537  \n","2000-04-01      -0.016087   -0.031280      0.007651  \n","2000-05-01       0.006745   -0.022159      0.031510  \n","...                   ...         ...           ...  \n","2022-08-01       0.011150   -0.043367      0.011058  \n","2022-09-01      -0.016411   -0.098049      0.001465  \n","2022-10-01       0.022900    0.076835     -0.008824  \n","2022-11-01      -0.005473    0.052358     -0.020142  \n","2022-12-01       0.005372   -0.060782     -0.006805  \n","\n","[276 rows x 196 columns]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-14-b86d5496bf3f>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[new_column_name] = data\n"]}]},{"cell_type":"code","source":["def split_sequences(sequences, no_steps_in, no_steps_out):\n","    X, y = list(), list()\n","    for i in range(len(sequences)):\n","        #find end of pattern\n","        end_ix = i + no_steps_in\n","        out_end_ix = end_ix + no_steps_out - 1\n","\n","        #check if we are beyond the dataset\n","        if out_end_ix > len(sequences):\n","            break\n","\n","        #gather input and output\n","        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix - 1:out_end_ix, -1]\n","        X.append(seq_x)\n","        y.append(seq_y)\n","\n","    return np.array(X), np.array(y)"],"metadata":{"id":"PwrS_f0Sw1bJ","executionInfo":{"status":"ok","timestamp":1694346324962,"user_tz":-60,"elapsed":17,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AcYmA4bAmJzr"},"source":["# Model implementation"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"OJ_C6OIKmJzs","executionInfo":{"status":"ok","timestamp":1694347662986,"user_tz":-60,"elapsed":231,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"outputs":[],"source":["def create_LSTM(no_features, no_steps_in, no_steps_out):\n","    units = 128 # 100?\n","    model = Sequential()\n","    model.add(LSTM(units, activation = 'tanh', return_sequences = True, input_shape = (no_steps_in, no_features)))\n","    model.add(LSTM(units, activation = 'tanh'))\n","    model.add(Dense(no_steps_out))\n","    model.compile(optimizer = keras.optimizers.Adam(learning_rate = 0.001),loss = 'mse')\n","    return model"]},{"cell_type":"markdown","source":["# Forecasting for 2022"],"metadata":{"id":"3DwYifaBxJct"}},{"cell_type":"code","source":["steps_in = 12 # use previous 12 observations to predict the next horizon\n","features = df.shape[1]\n","\n","#countries = ['Finland']\n","countries = ['Finland', 'United States', 'Germany', 'France', 'Spain', 'Italy', 'Netherlands', 'Sweden', 'Belgium', 'Denmark', 'Austria', 'Poland']\n","\n","\n","for (country, transformation) in zip(countries,transformations):\n","    warnings.filterwarnings('ignore')\n","\n","    print(\"country: \" + str(country))\n","    print()\n","\n","    # data (original) for reversing stationarity and calculating the RMSE\n","    split_point = len(df)-12\n","    original_inflation = \"original_inflation_\" + str(country)\n","    data_original = get_data(original_inflation, input_path_original)\n","    test_original = data_original[split_point:] # original inflation for 2022\n","\n","    # train data\n","    train = np.array(df.loc['2000-01-01':'2021-12-01'])\n","    train_out = np.array(df.loc['2000-01-01':'2021-12-01']['inflation_' + country])\n","\n","    # normalise features\n","    scaler = StandardScaler()\n","    scaler.fit(train)\n","    normalized_train = scaler.transform(train)\n","\n","    #normalized_train_out = target_scaler.transform(train_out)\n","    #normalized_train_out = normalized_train_out.reshape(len(normalized_train_out), 1)\n","\n","    # normalise target (needed especially for time series that aren't differenced because otherwise the scales are too different?)\n","    target_scaler = StandardScaler()\n","    train_out = train_out.reshape(len(train_out), 1)\n","    target_scaler.fit(train_out)\n","    normalized_train_out = target_scaler.transform(train_out)\n","\n","    train_set = np.hstack((normalized_train, normalized_train_out))\n","\n","    # out-of-sample-inputs\n","    test = np.array(df.loc['2021-01-01':'2021-12-01'])\n","    normalized_test = scaler.transform(test)\n","    test_set = normalized_test.reshape((1, steps_in, features))\n","\n","    horizons = [1,2,3,6,9,12]\n","\n","    for horizon in horizons:\n","        keras.utils.set_random_seed(42) # set random seed for reproducability\n","\n","        warnings.filterwarnings('ignore')\n","        print(\"horizon: \" + str(horizon))\n","        horizon_test = test_original[:horizon]\n","        forecast_df = pd.DataFrame(index=horizon_test.index)\n","        forecast_df['Actual'] = horizon_test['Data']\n","\n","        X,y = split_sequences(train_set, steps_in, horizon)\n","\n","        es = EarlyStopping(monitor = 'val_loss', mode = 'min', min_delta = 0.01, patience = 10,verbose = 0)\n","        model = create_LSTM(features, steps_in, horizon) # the model is trained specifically to forecast the horizon length\n","        print(model.summary())\n","        fit = model.fit(X, y, verbose=0, epochs=500, validation_split=0.1, callbacks = [es])\n","\n","        forecast_normalized = model.predict(test_set, verbose = 0)\n","        forecast_denormalized = target_scaler.inverse_transform(forecast_normalized)\n","        forecast = forecast_denormalized.flatten()\n","\n","        # we need to reverse the stationarity\n","        if transformation == \"FD\":\n","            print(\"Reversing the stationarity...\")\n","            last_observed_value = data_original[:split_point]\n","            last_observed_value = last_observed_value.values\n","            last_observed_value = last_observed_value[-1] # get the last observed value, i.e. 2021-12\n","\n","            forecasted_original = []\n","            for pred in forecast:\n","                forecasted_value = last_observed_value + pred\n","                forecasted_original.append(forecasted_value)\n","                last_observed_value = forecasted_value\n","            forecast = forecasted_original\n","            forecast = np.concatenate(forecast)\n","            forecast_df['Forecast'] = forecast\n","        else:\n","            forecast_df['Forecast'] = forecast\n","\n","        print\n","        print(\"forecast:\")\n","        print(forecast_df)\n","        print()\n","\n","        rmse = np.sqrt(mean_squared_error(forecast_df['Actual'], forecast_df['Forecast']))\n","        print('RMSE: ', rmse)\n","        print()\n","        print(\"######\")\n","\n","    print()\n","    print(\"##################\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UGdJCmDUxKno","executionInfo":{"status":"ok","timestamp":1694348183801,"user_tz":-60,"elapsed":506797,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}},"outputId":"ec75cb5d-11ba-4231-fb7e-738c2ddaa5a6"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["country: Finland\n","\n","horizon: 1\n","Model: \"sequential_72\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_144 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_145 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_72 (Dense)            (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 298113 (1.14 MB)\n","Trainable params: 298113 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.37452  3.604728\n","\n","RMSE:  0.7697918595743185\n","\n","######\n","horizon: 2\n","Model: \"sequential_73\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_146 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_147 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_73 (Dense)            (None, 2)                 258       \n","                                                                 \n","=================================================================\n","Total params: 298242 (1.14 MB)\n","Trainable params: 298242 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.37452  3.523136\n","2022-02-01  4.53068  3.458709\n","\n","RMSE:  0.9679814910883923\n","\n","######\n","horizon: 3\n","Model: \"sequential_74\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_148 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_149 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_74 (Dense)            (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 298371 (1.14 MB)\n","Trainable params: 298371 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.37452  3.497597\n","2022-02-01  4.53068  3.516266\n","2022-03-01  5.79765  3.468439\n","\n","RMSE:  1.5516930783824712\n","\n","######\n","horizon: 6\n","Model: \"sequential_75\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_150 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_151 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_75 (Dense)            (None, 6)                 774       \n","                                                                 \n","=================================================================\n","Total params: 298758 (1.14 MB)\n","Trainable params: 298758 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.37452  3.585165\n","2022-02-01  4.53068  3.503236\n","2022-03-01  5.79765  3.580832\n","2022-04-01  5.73817  3.572231\n","2022-05-01  6.96263  3.673385\n","2022-06-01  7.79233  3.782849\n","\n","RMSE:  2.5225436948149293\n","\n","######\n","horizon: 9\n","Model: \"sequential_76\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_152 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_153 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_76 (Dense)            (None, 9)                 1161      \n","                                                                 \n","=================================================================\n","Total params: 299145 (1.14 MB)\n","Trainable params: 299145 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.37452  3.572868\n","2022-02-01  4.53068  3.519884\n","2022-03-01  5.79765  3.468663\n","2022-04-01  5.73817  3.544113\n","2022-05-01  6.96263  3.611445\n","2022-06-01  7.79233  3.657738\n","2022-07-01  7.78545  3.674234\n","2022-08-01  7.61608  3.610183\n","2022-09-01  8.11930  3.680150\n","\n","RMSE:  3.21252878946361\n","\n","######\n","horizon: 12\n","Model: \"sequential_77\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_154 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_155 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_77 (Dense)            (None, 12)                1548      \n","                                                                 \n","=================================================================\n","Total params: 299532 (1.14 MB)\n","Trainable params: 299532 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.37452  3.607235\n","2022-02-01  4.53068  3.538100\n","2022-03-01  5.79765  3.506297\n","2022-04-01  5.73817  3.451643\n","2022-05-01  6.96263  3.509998\n","2022-06-01  7.79233  3.554908\n","2022-07-01  7.78545  3.645303\n","2022-08-01  7.61608  3.749880\n","2022-09-01  8.11930  3.903245\n","2022-10-01  8.31077  3.961375\n","2022-11-01  9.13824  3.926382\n","2022-12-01  9.14504  3.842473\n","\n","RMSE:  3.7192092608710996\n","\n","######\n","\n","##################\n","country: United States\n","\n","horizon: 1\n","Model: \"sequential_78\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_156 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_157 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_78 (Dense)            (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 298113 (1.14 MB)\n","Trainable params: 298113 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  7.47987  7.287747\n","\n","RMSE:  0.1921226072025295\n","\n","######\n","horizon: 2\n","Model: \"sequential_79\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_158 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_159 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_79 (Dense)            (None, 2)                 258       \n","                                                                 \n","=================================================================\n","Total params: 298242 (1.14 MB)\n","Trainable params: 298242 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  7.47987  7.000754\n","2022-02-01  7.87106  6.553405\n","\n","RMSE:  0.9914045794237788\n","\n","######\n","horizon: 3\n","Model: \"sequential_80\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_160 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_161 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_80 (Dense)            (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 298371 (1.14 MB)\n","Trainable params: 298371 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  7.47987  6.949644\n","2022-02-01  7.87106  6.520714\n","2022-03-01  8.54246  5.898259\n","\n","RMSE:  1.7412995776024283\n","\n","######\n","horizon: 6\n","Model: \"sequential_81\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_162 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_163 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_81 (Dense)            (None, 6)                 774       \n","                                                                 \n","=================================================================\n","Total params: 298758 (1.14 MB)\n","Trainable params: 298758 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  7.47987  7.195645\n","2022-02-01  7.87106  6.847054\n","2022-03-01  8.54246  6.413860\n","2022-04-01  8.25863  6.106435\n","2022-05-01  8.58151  6.182417\n","2022-06-01  9.05976  6.546207\n","\n","RMSE:  1.9307100865948084\n","\n","######\n","horizon: 9\n","Model: \"sequential_82\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_164 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_165 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_82 (Dense)            (None, 9)                 1161      \n","                                                                 \n","=================================================================\n","Total params: 299145 (1.14 MB)\n","Trainable params: 299145 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  7.47987  7.031099\n","2022-02-01  7.87106  6.677573\n","2022-03-01  8.54246  6.211229\n","2022-04-01  8.25863  6.063726\n","2022-05-01  8.58151  6.045308\n","2022-06-01  9.05976  6.221356\n","2022-07-01  8.52482  6.517324\n","2022-08-01  8.26269  6.714278\n","2022-09-01  8.20167  6.874839\n","\n","RMSE:  1.959450215650175\n","\n","######\n","horizon: 12\n","Model: \"sequential_83\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_166 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_167 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_83 (Dense)            (None, 12)                1548      \n","                                                                 \n","=================================================================\n","Total params: 299532 (1.14 MB)\n","Trainable params: 299532 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  7.47987  7.085142\n","2022-02-01  7.87106  6.697069\n","2022-03-01  8.54246  6.249925\n","2022-04-01  8.25863  5.903405\n","2022-05-01  8.58151  5.839527\n","2022-06-01  9.05976  5.917739\n","2022-07-01  8.52482  6.152025\n","2022-08-01  8.26269  6.558054\n","2022-09-01  8.20167  6.848339\n","2022-10-01  7.74543  6.820465\n","2022-11-01  7.11032  6.684221\n","2022-12-01  6.45440  6.373146\n","\n","RMSE:  1.8515490159409933\n","\n","######\n","\n","##################\n","country: Germany\n","\n","horizon: 1\n","Model: \"sequential_84\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_168 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_169 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_84 (Dense)            (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 298113 (1.14 MB)\n","Trainable params: 298113 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.15842  2.465291\n","\n","RMSE:  1.6931294535827632\n","\n","######\n","horizon: 2\n","Model: \"sequential_85\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_170 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_171 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_85 (Dense)            (None, 2)                 258       \n","                                                                 \n","=================================================================\n","Total params: 298242 (1.14 MB)\n","Trainable params: 298242 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.15842  2.337151\n","2022-02-01  4.33071  2.045921\n","\n","RMSE:  2.06606892544134\n","\n","######\n","horizon: 3\n","Model: \"sequential_86\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_172 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_173 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_86 (Dense)            (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 298371 (1.14 MB)\n","Trainable params: 298371 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.15842  2.165572\n","2022-02-01  4.33071  1.941344\n","2022-03-01  5.87659  1.803875\n","\n","RMSE:  2.9590268993716573\n","\n","######\n","horizon: 6\n","Model: \"sequential_87\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_174 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_175 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_87 (Dense)            (None, 6)                 774       \n","                                                                 \n","=================================================================\n","Total params: 298758 (1.14 MB)\n","Trainable params: 298758 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.15842  2.269788\n","2022-02-01  4.33071  2.170484\n","2022-03-01  5.87659  2.005729\n","2022-04-01  6.25000  1.706580\n","2022-05-01  7.01754  1.795405\n","2022-06-01  6.70554  1.794664\n","\n","RMSE:  3.984284486235581\n","\n","######\n","horizon: 9\n","Model: \"sequential_88\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_176 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_177 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_88 (Dense)            (None, 9)                 1161      \n","                                                                 \n","=================================================================\n","Total params: 299145 (1.14 MB)\n","Trainable params: 299145 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.15842  2.182983\n","2022-02-01  4.33071  2.063452\n","2022-03-01  5.87659  1.834874\n","2022-04-01  6.25000  1.795027\n","2022-05-01  7.01754  1.800391\n","2022-06-01  6.70554  1.871409\n","2022-07-01  6.67311  1.994696\n","2022-08-01  6.95652  1.777426\n","2022-09-01  8.57418  1.925519\n","\n","RMSE:  4.579274469677585\n","\n","######\n","horizon: 12\n","Model: \"sequential_89\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_178 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_179 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_89 (Dense)            (None, 12)                1548      \n","                                                                 \n","=================================================================\n","Total params: 299532 (1.14 MB)\n","Trainable params: 299532 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.15842  2.504569\n","2022-02-01  4.33071  2.053835\n","2022-03-01  5.87659  1.779638\n","2022-04-01  6.25000  1.729250\n","2022-05-01  7.01754  1.916263\n","2022-06-01  6.70554  1.993115\n","2022-07-01  6.67311  1.976268\n","2022-08-01  6.95652  1.829720\n","2022-09-01  8.57418  1.970569\n","2022-10-01  8.82071  1.664302\n","2022-11-01  8.80383  1.685132\n","2022-12-01  8.11843  1.745151\n","\n","RMSE:  5.226792989578554\n","\n","######\n","\n","##################\n","country: France\n","\n","horizon: 1\n","Model: \"sequential_90\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_180 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_181 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_90 (Dense)            (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 298113 (1.14 MB)\n","Trainable params: 298113 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  2.85388  2.908297\n","\n","RMSE:  0.054417365956306085\n","\n","######\n","horizon: 2\n","Model: \"sequential_91\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_182 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_183 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_91 (Dense)            (None, 2)                 258       \n","                                                                 \n","=================================================================\n","Total params: 298242 (1.14 MB)\n","Trainable params: 298242 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  2.85388  2.726331\n","2022-02-01  3.63394  2.494368\n","\n","RMSE:  0.8108311099567874\n","\n","######\n","horizon: 3\n","Model: \"sequential_92\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_184 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_185 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_92 (Dense)            (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 298371 (1.14 MB)\n","Trainable params: 298371 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  2.85388  2.715675\n","2022-02-01  3.63394  2.551414\n","2022-03-01  4.48227  2.316384\n","\n","RMSE:  1.4002410380304136\n","\n","######\n","horizon: 6\n","Model: \"sequential_93\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_186 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_187 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_93 (Dense)            (None, 6)                 774       \n","                                                                 \n","=================================================================\n","Total params: 298758 (1.14 MB)\n","Trainable params: 298758 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  2.85388  2.709336\n","2022-02-01  3.63394  2.500424\n","2022-03-01  4.48227  2.326124\n","2022-04-01  4.82713  2.222409\n","2022-05-01  5.19774  2.204831\n","2022-06-01  5.83976  2.258089\n","\n","RMSE:  2.398790284788304\n","\n","######\n","horizon: 9\n","Model: \"sequential_94\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_188 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_189 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_94 (Dense)            (None, 9)                 1161      \n","                                                                 \n","=================================================================\n","Total params: 299145 (1.14 MB)\n","Trainable params: 299145 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  2.85388  2.705691\n","2022-02-01  3.63394  2.508495\n","2022-03-01  4.48227  2.301870\n","2022-04-01  4.82713  2.218099\n","2022-05-01  5.19774  2.236675\n","2022-06-01  5.83976  2.294927\n","2022-07-01  6.08083  2.369097\n","2022-08-01  5.91313  2.362476\n","2022-09-01  5.55192  2.424405\n","\n","RMSE:  2.7958099780661176\n","\n","######\n","horizon: 12\n","Model: \"sequential_95\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_190 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_191 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_95 (Dense)            (None, 12)                1548      \n","                                                                 \n","=================================================================\n","Total params: 299532 (1.14 MB)\n","Trainable params: 299532 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  2.85388  2.832454\n","2022-02-01  3.63394  2.636176\n","2022-03-01  4.48227  2.418501\n","2022-04-01  4.82713  2.264204\n","2022-05-01  5.19774  2.230716\n","2022-06-01  5.83976  2.272860\n","2022-07-01  6.08083  2.433930\n","2022-08-01  5.91313  2.588948\n","2022-09-01  5.55192  2.698102\n","2022-10-01  6.20047  2.683885\n","2022-11-01  6.15013  2.673068\n","2022-12-01  5.85072  2.630785\n","\n","RMSE:  2.8963825100128116\n","\n","######\n","\n","##################\n","country: Spain\n","\n","horizon: 1\n","Model: \"sequential_96\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_192 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_193 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_96 (Dense)            (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 298113 (1.14 MB)\n","Trainable params: 298113 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  6.13222  6.718909\n","\n","RMSE:  0.5866894470977781\n","\n","######\n","horizon: 2\n","Model: \"sequential_97\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_194 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_195 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_97 (Dense)            (None, 2)                 258       \n","                                                                 \n","=================================================================\n","Total params: 298242 (1.14 MB)\n","Trainable params: 298242 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  6.13222  6.508361\n","2022-02-01  7.62308  5.960231\n","\n","RMSE:  1.2055185602436405\n","\n","######\n","horizon: 3\n","Model: \"sequential_98\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_196 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_197 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_98 (Dense)            (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 298371 (1.14 MB)\n","Trainable params: 298371 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  6.13222  6.408795\n","2022-02-01  7.62308  5.993299\n","2022-03-01  9.81838  5.581276\n","\n","RMSE:  2.62587989154529\n","\n","######\n","horizon: 6\n","Model: \"sequential_99\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_198 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_199 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_99 (Dense)            (None, 6)                 774       \n","                                                                 \n","=================================================================\n","Total params: 298758 (1.14 MB)\n","Trainable params: 298758 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","              Actual  Forecast\n","Date                          \n","2022-01-01   6.13222  6.496086\n","2022-02-01   7.62308  6.040878\n","2022-03-01   9.81838  5.721140\n","2022-04-01   8.34469  5.478663\n","2022-05-01   8.72735  5.385073\n","2022-06-01  10.21630  5.433039\n","\n","RMSE:  3.206442891207978\n","\n","######\n","horizon: 9\n","Model: \"sequential_100\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_200 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_201 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_100 (Dense)           (None, 9)                 1161      \n","                                                                 \n","=================================================================\n","Total params: 299145 (1.14 MB)\n","Trainable params: 299145 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","              Actual  Forecast\n","Date                          \n","2022-01-01   6.13222  6.428498\n","2022-02-01   7.62308  5.962763\n","2022-03-01   9.81838  5.479091\n","2022-04-01   8.34469  5.274859\n","2022-05-01   8.72735  5.163856\n","2022-06-01  10.21630  5.274494\n","2022-07-01  10.77025  5.306229\n","2022-08-01  10.54911  5.257762\n","2022-09-01   8.87199  5.144520\n","\n","RMSE:  3.943568415682664\n","\n","######\n","horizon: 12\n","Model: \"sequential_101\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_202 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_203 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_101 (Dense)           (None, 12)                1548      \n","                                                                 \n","=================================================================\n","Total params: 299532 (1.14 MB)\n","Trainable params: 299532 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","              Actual  Forecast\n","Date                          \n","2022-01-01   6.13222  6.479424\n","2022-02-01   7.62308  5.954100\n","2022-03-01   9.81838  5.408130\n","2022-04-01   8.34469  5.029558\n","2022-05-01   8.72735  4.954421\n","2022-06-01  10.21630  4.993298\n","2022-07-01  10.77025  5.091948\n","2022-08-01  10.54911  5.308043\n","2022-09-01   8.87199  5.406365\n","2022-10-01   7.26483  5.291247\n","2022-11-01   6.80956  5.146490\n","2022-12-01   5.70769  4.959342\n","\n","RMSE:  3.580089693614801\n","\n","######\n","\n","##################\n","country: Italy\n","\n","horizon: 1\n","Model: \"sequential_102\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_204 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_205 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_102 (Dense)           (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 298113 (1.14 MB)\n","Trainable params: 298113 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.84027  4.187892\n","\n","RMSE:  0.6523777784156799\n","\n","######\n","horizon: 2\n","Model: \"sequential_103\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_206 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_207 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_103 (Dense)           (None, 2)                 258       \n","                                                                 \n","=================================================================\n","Total params: 298242 (1.14 MB)\n","Trainable params: 298242 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.84027  4.054831\n","2022-02-01  5.70600  4.109265\n","\n","RMSE:  1.258268266364933\n","\n","######\n","horizon: 3\n","Model: \"sequential_104\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_208 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_209 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_104 (Dense)           (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 298371 (1.14 MB)\n","Trainable params: 298371 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.84027  3.985269\n","2022-02-01  5.70600  3.939747\n","2022-03-01  6.46095  3.729846\n","\n","RMSE:  1.9416145935614726\n","\n","######\n","horizon: 6\n","Model: \"sequential_105\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_210 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_211 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_105 (Dense)           (None, 6)                 774       \n","                                                                 \n","=================================================================\n","Total params: 298758 (1.14 MB)\n","Trainable params: 298758 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.84027  4.097506\n","2022-02-01  5.70600  4.060231\n","2022-03-01  6.46095  3.925067\n","2022-04-01  5.95581  3.783764\n","2022-05-01  6.82037  3.666374\n","2022-06-01  7.96545  3.606727\n","\n","RMSE:  2.6880878755336894\n","\n","######\n","horizon: 9\n","Model: \"sequential_106\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_212 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_213 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_106 (Dense)           (None, 9)                 1161      \n","                                                                 \n","=================================================================\n","Total params: 299145 (1.14 MB)\n","Trainable params: 299145 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.84027  4.008796\n","2022-02-01  5.70600  3.973320\n","2022-03-01  6.46095  3.839900\n","2022-04-01  5.95581  3.739593\n","2022-05-01  6.82037  3.685910\n","2022-06-01  7.96545  3.674569\n","2022-07-01  7.92741  3.756485\n","2022-08-01  8.37298  3.822476\n","2022-09-01  8.86559  3.918684\n","\n","RMSE:  3.4365216316828544\n","\n","######\n","horizon: 12\n","Model: \"sequential_107\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_214 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_215 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_107 (Dense)           (None, 12)                1548      \n","                                                                 \n","=================================================================\n","Total params: 299532 (1.14 MB)\n","Trainable params: 299532 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","              Actual  Forecast\n","Date                          \n","2022-01-01   4.84027  4.076744\n","2022-02-01   5.70600  4.026652\n","2022-03-01   6.46095  3.935914\n","2022-04-01   5.95581  3.802552\n","2022-05-01   6.82037  3.730402\n","2022-06-01   7.96545  3.675008\n","2022-07-01   7.92741  3.739004\n","2022-08-01   8.37298  3.906127\n","2022-09-01   8.86559  4.115952\n","2022-10-01  11.83712  4.186478\n","2022-11-01  11.77024  4.228836\n","2022-12-01  11.63227  4.222851\n","\n","RMSE:  4.767340922551605\n","\n","######\n","\n","##################\n","country: Netherlands\n","\n","horizon: 1\n","Model: \"sequential_108\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_216 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_217 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_108 (Dense)           (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 298113 (1.14 MB)\n","Trainable params: 298113 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  6.42074  6.029701\n","\n","RMSE:  0.3910387972354892\n","\n","######\n","horizon: 2\n","Model: \"sequential_109\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_218 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_219 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_109 (Dense)           (None, 2)                 258       \n","                                                                 \n","=================================================================\n","Total params: 298242 (1.14 MB)\n","Trainable params: 298242 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  6.42074  5.956971\n","2022-02-01  6.17113  5.917791\n","\n","RMSE:  0.3736729742910053\n","\n","######\n","horizon: 3\n","Model: \"sequential_110\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_220 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_221 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_110 (Dense)           (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 298371 (1.14 MB)\n","Trainable params: 298371 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  6.42074  5.776497\n","2022-02-01  6.17113  5.686856\n","2022-03-01  9.72720  5.575711\n","\n","RMSE:  2.441613809171789\n","\n","######\n","horizon: 6\n","Model: \"sequential_111\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_222 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_223 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_111 (Dense)           (None, 6)                 774       \n","                                                                 \n","=================================================================\n","Total params: 298758 (1.14 MB)\n","Trainable params: 298758 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  6.42074  5.836466\n","2022-02-01  6.17113  5.757118\n","2022-03-01  9.72720  5.623286\n","2022-04-01  9.55560  5.519486\n","2022-05-01  8.76119  5.464137\n","2022-06-01  8.55293  5.621238\n","\n","RMSE:  2.9751887437708313\n","\n","######\n","horizon: 9\n","Model: \"sequential_112\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_224 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_225 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_112 (Dense)           (None, 9)                 1161      \n","                                                                 \n","=================================================================\n","Total params: 299145 (1.14 MB)\n","Trainable params: 299145 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","              Actual  Forecast\n","Date                          \n","2022-01-01   6.42074  5.829449\n","2022-02-01   6.17113  5.663212\n","2022-03-01   9.72720  5.420852\n","2022-04-01   9.55560  5.332347\n","2022-05-01   8.76119  5.417756\n","2022-06-01   8.55293  5.623133\n","2022-07-01  10.28758  5.844709\n","2022-08-01  11.95917  6.002072\n","2022-09-01  14.53200  6.078378\n","\n","RMSE:  4.514670111259578\n","\n","######\n","horizon: 12\n","Model: \"sequential_113\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_226 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_227 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_113 (Dense)           (None, 12)                1548      \n","                                                                 \n","=================================================================\n","Total params: 299532 (1.14 MB)\n","Trainable params: 299532 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","              Actual  Forecast\n","Date                          \n","2022-01-01   6.42074  5.909839\n","2022-02-01   6.17113  5.731941\n","2022-03-01   9.72720  5.531866\n","2022-04-01   9.55560  5.248561\n","2022-05-01   8.76119  5.137608\n","2022-06-01   8.55293  5.203309\n","2022-07-01  10.28758  5.441854\n","2022-08-01  11.95917  5.743386\n","2022-09-01  14.53200  6.074827\n","2022-10-01  14.32519  6.131728\n","2022-11-01   9.87894  5.956244\n","2022-12-01   9.58688  5.714483\n","\n","RMSE:  4.933830957536985\n","\n","######\n","\n","##################\n","country: Sweden\n","\n","horizon: 1\n","Model: \"sequential_114\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_228 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_229 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_114 (Dense)           (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 298113 (1.14 MB)\n","Trainable params: 298113 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  3.68837  2.350352\n","\n","RMSE:  1.3380179511260986\n","\n","######\n","horizon: 2\n","Model: \"sequential_115\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_230 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_231 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_115 (Dense)           (None, 2)                 258       \n","                                                                 \n","=================================================================\n","Total params: 298242 (1.14 MB)\n","Trainable params: 298242 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  3.68837  2.576339\n","2022-02-01  4.29191  2.291579\n","\n","RMSE:  1.6183228749185146\n","\n","######\n","horizon: 3\n","Model: \"sequential_116\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_232 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_233 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_116 (Dense)           (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 298371 (1.14 MB)\n","Trainable params: 298371 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  3.68837  1.927477\n","2022-02-01  4.29191  2.275064\n","2022-03-01  5.96690  2.027021\n","\n","RMSE:  2.7502153619584098\n","\n","######\n","horizon: 6\n","Model: \"sequential_117\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_234 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_235 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_117 (Dense)           (None, 6)                 774       \n","                                                                 \n","=================================================================\n","Total params: 298758 (1.14 MB)\n","Trainable params: 298758 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  3.68837  2.284024\n","2022-02-01  4.29191  2.257206\n","2022-03-01  5.96690  2.262805\n","2022-04-01  6.36073  2.284353\n","2022-05-01  7.26601  2.284760\n","2022-06-01  8.68100  2.375040\n","\n","RMSE:  4.103400122028997\n","\n","######\n","horizon: 9\n","Model: \"sequential_118\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_236 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_237 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_118 (Dense)           (None, 9)                 1161      \n","                                                                 \n","=================================================================\n","Total params: 299145 (1.14 MB)\n","Trainable params: 299145 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","              Actual  Forecast\n","Date                          \n","2022-01-01   3.68837  2.117570\n","2022-02-01   4.29191  2.285236\n","2022-03-01   5.96690  2.246802\n","2022-04-01   6.36073  2.360119\n","2022-05-01   7.26601  2.331881\n","2022-06-01   8.68100  2.448913\n","2022-07-01   8.48844  2.609018\n","2022-08-01   9.83168  2.301159\n","2022-09-01  10.83762  2.378413\n","\n","RMSE:  5.399148461783061\n","\n","######\n","horizon: 12\n","Model: \"sequential_119\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_238 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_239 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_119 (Dense)           (None, 12)                1548      \n","                                                                 \n","=================================================================\n","Total params: 299532 (1.14 MB)\n","Trainable params: 299532 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","              Actual  Forecast\n","Date                          \n","2022-01-01   3.68837  2.036482\n","2022-02-01   4.29191  1.945650\n","2022-03-01   5.96690  2.126082\n","2022-04-01   6.36073  2.328097\n","2022-05-01   7.26601  2.404024\n","2022-06-01   8.68100  2.466601\n","2022-07-01   8.48844  2.727452\n","2022-08-01   9.83168  2.568576\n","2022-09-01  10.83762  2.733050\n","2022-10-01  10.85325  2.508058\n","2022-11-01  11.46453  2.182096\n","2022-12-01  12.33864  2.400001\n","\n","RMSE:  6.504571612841827\n","\n","######\n","\n","##################\n","country: Belgium\n","\n","horizon: 1\n","Model: \"sequential_120\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_240 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_241 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_120 (Dense)           (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 298113 (1.14 MB)\n","Trainable params: 298113 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  7.59298  3.416348\n","\n","RMSE:  4.1766324963378905\n","\n","######\n","horizon: 2\n","Model: \"sequential_121\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_242 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_243 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_121 (Dense)           (None, 2)                 258       \n","                                                                 \n","=================================================================\n","Total params: 298242 (1.14 MB)\n","Trainable params: 298242 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  7.59298  3.268880\n","2022-02-01  8.03920  3.036914\n","\n","RMSE:  4.675505634738103\n","\n","######\n","horizon: 3\n","Model: \"sequential_122\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_244 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_245 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_122 (Dense)           (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 298371 (1.14 MB)\n","Trainable params: 298371 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  7.59298  2.561064\n","2022-02-01  8.03920  2.747776\n","2022-03-01  8.30694  2.357160\n","\n","RMSE:  5.438113427617924\n","\n","######\n","horizon: 6\n","Model: \"sequential_123\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_246 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_247 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_123 (Dense)           (None, 6)                 774       \n","                                                                 \n","=================================================================\n","Total params: 298758 (1.14 MB)\n","Trainable params: 298758 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  7.59298  3.157736\n","2022-02-01  8.03920  3.083705\n","2022-03-01  8.30694  3.008733\n","2022-04-01  8.30628  2.741947\n","2022-05-01  8.96893  2.755632\n","2022-06-01  9.64960  2.931417\n","\n","RMSE:  5.582713957727908\n","\n","######\n","horizon: 9\n","Model: \"sequential_124\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_248 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_249 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_124 (Dense)           (None, 9)                 1161      \n","                                                                 \n","=================================================================\n","Total params: 299145 (1.14 MB)\n","Trainable params: 299145 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","              Actual  Forecast\n","Date                          \n","2022-01-01   7.59298  3.163288\n","2022-02-01   8.03920  3.085155\n","2022-03-01   8.30694  2.830899\n","2022-04-01   8.30628  2.897755\n","2022-05-01   8.96893  2.847019\n","2022-06-01   9.64960  2.859231\n","2022-07-01   9.62138  2.874180\n","2022-08-01   9.94416  2.637976\n","2022-09-01  11.27499  3.023476\n","\n","RMSE:  6.27148155529353\n","\n","######\n","horizon: 12\n","Model: \"sequential_125\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_250 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_251 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_125 (Dense)           (None, 12)                1548      \n","                                                                 \n","=================================================================\n","Total params: 299532 (1.14 MB)\n","Trainable params: 299532 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","              Actual  Forecast\n","Date                          \n","2022-01-01   7.59298  3.048530\n","2022-02-01   8.03920  2.856790\n","2022-03-01   8.30694  2.967164\n","2022-04-01   8.30628  3.214767\n","2022-05-01   8.96893  3.218510\n","2022-06-01   9.64960  3.284180\n","2022-07-01   9.62138  3.310728\n","2022-08-01   9.94416  3.341934\n","2022-09-01  11.27499  3.494581\n","2022-10-01  12.26795  3.123083\n","2022-11-01  10.62873  2.878507\n","2022-12-01  10.35079  2.871377\n","\n","RMSE:  6.5772124230100255\n","\n","######\n","\n","##################\n","country: Denmark\n","\n","horizon: 1\n","Model: \"sequential_126\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_252 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_253 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_126 (Dense)           (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 298113 (1.14 MB)\n","Trainable params: 298113 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.34363  3.144392\n","\n","RMSE:  1.1992375747323036\n","\n","######\n","horizon: 2\n","Model: \"sequential_127\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_254 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_255 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_127 (Dense)           (None, 2)                 258       \n","                                                                 \n","=================================================================\n","Total params: 298242 (1.14 MB)\n","Trainable params: 298242 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.34363  3.080605\n","2022-02-01  4.79846  2.871666\n","\n","RMSE:  1.629074253790296\n","\n","######\n","horizon: 3\n","Model: \"sequential_128\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_256 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_257 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_128 (Dense)           (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 298371 (1.14 MB)\n","Trainable params: 298371 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.34363  3.251677\n","2022-02-01  4.79846  3.148110\n","2022-03-01  5.36913  3.037418\n","\n","RMSE:  1.7656819491672506\n","\n","######\n","horizon: 6\n","Model: \"sequential_129\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_258 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_259 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_129 (Dense)           (None, 6)                 774       \n","                                                                 \n","=================================================================\n","Total params: 298758 (1.14 MB)\n","Trainable params: 298758 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.34363  3.160049\n","2022-02-01  4.79846  2.988855\n","2022-03-01  5.36913  2.794212\n","2022-04-01  6.68577  2.678655\n","2022-05-01  7.43565  2.625505\n","2022-06-01  8.19048  2.793083\n","\n","RMSE:  3.6430780215955134\n","\n","######\n","horizon: 9\n","Model: \"sequential_130\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_260 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_261 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_130 (Dense)           (None, 9)                 1161      \n","                                                                 \n","=================================================================\n","Total params: 299145 (1.14 MB)\n","Trainable params: 299145 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","              Actual  Forecast\n","Date                          \n","2022-01-01   4.34363  3.169561\n","2022-02-01   4.79846  3.065676\n","2022-03-01   5.36913  2.951722\n","2022-04-01   6.68577  3.042971\n","2022-05-01   7.43565  3.132400\n","2022-06-01   8.19048  3.365059\n","2022-07-01   8.70388  3.476928\n","2022-08-01   8.90995  3.463005\n","2022-09-01  10.01890  3.339608\n","\n","RMSE:  4.306334540900511\n","\n","######\n","horizon: 12\n","Model: \"sequential_131\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_262 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_263 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_131 (Dense)           (None, 12)                1548      \n","                                                                 \n","=================================================================\n","Total params: 299532 (1.14 MB)\n","Trainable params: 299532 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","              Actual  Forecast\n","Date                          \n","2022-01-01   4.34363  3.189287\n","2022-02-01   4.79846  3.034318\n","2022-03-01   5.36913  2.898386\n","2022-04-01   6.68577  2.802976\n","2022-05-01   7.43565  2.793282\n","2022-06-01   8.19048  2.963328\n","2022-07-01   8.70388  3.182912\n","2022-08-01   8.90995  3.315767\n","2022-09-01  10.01890  3.330782\n","2022-10-01  10.11236  3.167154\n","2022-11-01   8.87021  2.932521\n","2022-12-01   8.72420  2.699226\n","\n","RMSE:  5.0066566177167475\n","\n","######\n","\n","##################\n","country: Austria\n","\n","horizon: 1\n","Model: \"sequential_132\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_264 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_265 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_132 (Dense)           (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 298113 (1.14 MB)\n","Trainable params: 298113 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.98505  3.077977\n","\n","RMSE:  1.9070732963562014\n","\n","######\n","horizon: 2\n","Model: \"sequential_133\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_266 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_267 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_133 (Dense)           (None, 2)                 258       \n","                                                                 \n","=================================================================\n","Total params: 298242 (1.14 MB)\n","Trainable params: 298242 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.98505  3.039943\n","2022-02-01  5.75397  2.650300\n","\n","RMSE:  2.5900006899534866\n","\n","######\n","horizon: 3\n","Model: \"sequential_134\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_268 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_269 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_134 (Dense)           (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 298371 (1.14 MB)\n","Trainable params: 298371 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.98505  2.710957\n","2022-02-01  5.75397  2.604737\n","2022-03-01  6.77135  2.492756\n","\n","RMSE:  3.3364419430420806\n","\n","######\n","horizon: 6\n","Model: \"sequential_135\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_270 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_271 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_135 (Dense)           (None, 6)                 774       \n","                                                                 \n","=================================================================\n","Total params: 298758 (1.14 MB)\n","Trainable params: 298758 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","             Actual  Forecast\n","Date                         \n","2022-01-01  4.98505  2.792662\n","2022-02-01  5.75397  2.897283\n","2022-03-01  6.77135  3.057420\n","2022-04-01  7.17092  2.870117\n","2022-05-01  7.73751  2.739759\n","2022-06-01  8.67446  2.811371\n","\n","RMSE:  4.175538288352873\n","\n","######\n","horizon: 9\n","Model: \"sequential_136\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_272 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_273 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_136 (Dense)           (None, 9)                 1161      \n","                                                                 \n","=================================================================\n","Total params: 299145 (1.14 MB)\n","Trainable params: 299145 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","              Actual  Forecast\n","Date                          \n","2022-01-01   4.98505  2.951649\n","2022-02-01   5.75397  3.023926\n","2022-03-01   6.77135  2.811832\n","2022-04-01   7.17092  2.909621\n","2022-05-01   7.73751  2.749716\n","2022-06-01   8.67446  2.731163\n","2022-07-01   9.42663  2.576979\n","2022-08-01   9.32039  2.486853\n","2022-09-01  10.62802  2.446154\n","\n","RMSE:  5.438372369448895\n","\n","######\n","horizon: 12\n","Model: \"sequential_137\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_274 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_275 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_137 (Dense)           (None, 12)                1548      \n","                                                                 \n","=================================================================\n","Total params: 299532 (1.14 MB)\n","Trainable params: 299532 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","forecast:\n","              Actual  Forecast\n","Date                          \n","2022-01-01   4.98505  3.027464\n","2022-02-01   5.75397  2.895630\n","2022-03-01   6.77135  2.789603\n","2022-04-01   7.17092  2.851459\n","2022-05-01   7.73751  2.780955\n","2022-06-01   8.67446  2.941953\n","2022-07-01   9.42663  2.751178\n","2022-08-01   9.32039  2.588618\n","2022-09-01  10.62802  2.682023\n","2022-10-01  11.04707  2.266219\n","2022-11-01  10.59160  2.097222\n","2022-12-01  10.15180  2.215779\n","\n","RMSE:  6.252991834961887\n","\n","######\n","\n","##################\n","country: Poland\n","\n","horizon: 1\n","Model: \"sequential_138\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_276 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_277 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_138 (Dense)           (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 298113 (1.14 MB)\n","Trainable params: 298113 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","            Actual  Forecast\n","Date                        \n","2022-01-01     9.4  9.045882\n","\n","RMSE:  0.3541183054447181\n","\n","######\n","horizon: 2\n","Model: \"sequential_139\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_278 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_279 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_139 (Dense)           (None, 2)                 258       \n","                                                                 \n","=================================================================\n","Total params: 298242 (1.14 MB)\n","Trainable params: 298242 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","            Actual  Forecast\n","Date                        \n","2022-01-01     9.4  8.546550\n","2022-02-01     8.5  8.200136\n","\n","RMSE:  0.6396467917752806\n","\n","######\n","horizon: 3\n","Model: \"sequential_140\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_280 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_281 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_140 (Dense)           (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 298371 (1.14 MB)\n","Trainable params: 298371 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","            Actual  Forecast\n","Date                        \n","2022-01-01     9.4  8.267573\n","2022-02-01     8.5  7.956599\n","2022-03-01    11.0  7.482614\n","\n","RMSE:  2.156361164667057\n","\n","######\n","horizon: 6\n","Model: \"sequential_141\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_282 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_283 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_141 (Dense)           (None, 6)                 774       \n","                                                                 \n","=================================================================\n","Total params: 298758 (1.14 MB)\n","Trainable params: 298758 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","            Actual  Forecast\n","Date                        \n","2022-01-01     9.4  8.547975\n","2022-02-01     8.5  8.203741\n","2022-03-01    11.0  7.823304\n","2022-04-01    12.4  7.444297\n","2022-05-01    13.9  7.116373\n","2022-06-01    15.5  7.000903\n","\n","RMSE:  5.061560368054659\n","\n","######\n","horizon: 9\n","Model: \"sequential_142\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_284 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_285 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_142 (Dense)           (None, 9)                 1161      \n","                                                                 \n","=================================================================\n","Total params: 299145 (1.14 MB)\n","Trainable params: 299145 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","            Actual  Forecast\n","Date                        \n","2022-01-01     9.4  8.734285\n","2022-02-01     8.5  8.478049\n","2022-03-01    11.0  8.040902\n","2022-04-01    12.4  7.724270\n","2022-05-01    13.9  7.690057\n","2022-06-01    15.5  7.807781\n","2022-07-01    15.6  7.978018\n","2022-08-01    16.1  8.274317\n","2022-09-01    17.2  8.617906\n","\n","RMSE:  5.97944851430962\n","\n","######\n","horizon: 12\n","Model: \"sequential_143\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_286 (LSTM)             (None, 12, 128)           166400    \n","                                                                 \n"," lstm_287 (LSTM)             (None, 128)               131584    \n","                                                                 \n"," dense_143 (Dense)           (None, 12)                1548      \n","                                                                 \n","=================================================================\n","Total params: 299532 (1.14 MB)\n","Trainable params: 299532 (1.14 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Reversing the stationarity...\n","forecast:\n","            Actual  Forecast\n","Date                        \n","2022-01-01     9.4  8.853027\n","2022-02-01     8.5  8.650647\n","2022-03-01    11.0  8.220076\n","2022-04-01    12.4  7.850383\n","2022-05-01    13.9  7.726363\n","2022-06-01    15.5  7.771784\n","2022-07-01    15.6  7.993229\n","2022-08-01    16.1  8.326781\n","2022-09-01    17.2  8.593926\n","2022-10-01    17.9  8.598397\n","2022-11-01    17.5  8.299804\n","2022-12-01    16.6  8.054706\n","\n","RMSE:  6.850327644047226\n","\n","######\n","\n","##################\n"]}]},{"cell_type":"markdown","source":["### Forecasting for 2022 full year (old code for reference)"],"metadata":{"id":"EVt3h9sHny8z"}},{"cell_type":"code","execution_count":18,"metadata":{"id":"XLl9s5Q1mJzt","colab":{"base_uri":"https://localhost:8080/","height":512},"executionInfo":{"status":"error","timestamp":1694347327919,"user_tz":-60,"elapsed":24,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}},"outputId":"538b08ee-f4c4-4b69-b4c1-6243e1edaf35"},"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'hicp_Finland_LD'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-85feb5e125f4>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2020-01-01'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'2021-12-01'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2000-01-01'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'2019-12-01'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hicp_Finland_LD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mval_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2020-01-01'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'2021-12-01'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hicp_Finland_LD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'hicp_Finland_LD'"]}],"source":["# 80/10/10 split is usually recommended\n","# here could do that 2 years for validation and 1 year for out-of-sample testing\n","\n","train = np.array(df.loc['2000-01-01':'2019-12-01'])\n","val = np.array(df.loc['2020-01-01':'2021-12-01'])\n","\n","out = np.array(df.loc['2000-01-01':'2019-12-01']['hicp_Finland_LD'])\n","val_out = np.array(df.loc['2020-01-01':'2021-12-01']['hicp_Finland_LD'])\n","\n","out = out.reshape(len(out), 1)\n","val_out = val_out.reshape(len(val_out), 1)\n","\n","# out-of-sample inputs\n","test_set = np.array(df.loc['2021-01-01':'2021-12-01'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cpxo5RnMmJzt","executionInfo":{"status":"aborted","timestamp":1694347327920,"user_tz":-60,"elapsed":16,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"outputs":[],"source":["# scale\n","#scaler = preprocessing.StandardScaler()\n","#scaler.fit(train)\n","\n","#train_set = scaler.transform(train)\n","#val_set = scaler.transform(val)\n","#test_set = scaler.transform(test_set)\n","\n","train_set = np.hstack((train, out))\n","val_set = np.hstack((val, val_out))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GmMvhj9GmJzu","executionInfo":{"status":"aborted","timestamp":1694347327920,"user_tz":-60,"elapsed":15,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"outputs":[],"source":["# timesteps\n","no_steps_in, no_steps_out = 12, 12 # use 12 data points to predict the next 12 data points\n","\n","train_X, train_y = split_sequences(train_set, no_steps_in, no_steps_out)\n","print(train_X.shape, train_y.shape)\n","val_X, val_y = split_sequences(val_set, no_steps_in, no_steps_out)\n","print(val_X.shape, val_y.shape)\n","test_set = test_set.reshape((1, no_steps_in, no_variables))\n","print(test_set.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ElWUEDS_mJzu","executionInfo":{"status":"aborted","timestamp":1694347327920,"user_tz":-60,"elapsed":15,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"outputs":[],"source":["model = create_LSTM(no_variables, no_steps_in, no_steps_out)\n","\n","es = EarlyStopping(monitor = 'val_loss', mode = 'min', min_delta = 0.01, patience = 30, verbose = 0)\n","\n","fit = model.fit(train_X, train_y, validation_data = (val_X, val_y), epochs = 500, verbose = 0, callbacks = [es])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IsmHTeFZmJzu","executionInfo":{"status":"aborted","timestamp":1694347327921,"user_tz":-60,"elapsed":16,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"outputs":[],"source":["print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W7n623QcmJzu","executionInfo":{"status":"aborted","timestamp":1694347327921,"user_tz":-60,"elapsed":16,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"outputs":[],"source":["fig, ax = plt.subplots(1,1)\n","ax.plot(fit.history['loss'], color = 'blue')\n","ax.plot(fit.history['val_loss'], label = 'red', color = 'DarkRed')\n","ax.legend([\"training\", \"validation\"])\n","fig.set_size_inches(12,3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0XFtG06rmJzu","executionInfo":{"status":"aborted","timestamp":1694347327921,"user_tz":-60,"elapsed":16,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"outputs":[],"source":["actual = df.loc['2022-01-01':'2022-12-01']['hicp_Finland_LD']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ma4FN5qimJzu","executionInfo":{"status":"aborted","timestamp":1694347327921,"user_tz":-60,"elapsed":15,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"outputs":[],"source":["pred = model.predict(test_set, verbose = 0)\n","print(pred.shape)\n","pred = pred.reshape(pred.shape[1])\n","pred = (pd.DataFrame(pred, index=actual.index))\n","print(pred.shape)\n","print(pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wxKfGFG5mJzu","executionInfo":{"status":"aborted","timestamp":1694347327922,"user_tz":-60,"elapsed":16,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"outputs":[],"source":["#pred = np.transpose([pred] * no_variables) # need to inverse transform and hence same shape is required as when it was transformed\n","#pred = scaler.inverse_transform(pred)\n","#pred = pred[:,0]\n","#pred = (pd.DataFrame(pred, index=actual.index))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i3uu40R7mJzu","executionInfo":{"status":"aborted","timestamp":1694347327922,"user_tz":-60,"elapsed":16,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"outputs":[],"source":["rmse = np.sqrt(mean_squared_error(actual, pred))\n","print('Test RMSE: %.6f' % rmse)\n","\n","fig, ax = plt.subplots(1,1)\n","ax.plot(actual, color='blue')\n","ax.plot(pred, color='red')\n","ax.legend(['actual', 'predicted'])\n","ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n","ax.set_xlim(actual.index[0], actual.index[len(actual)-1])\n","#ax.set_title(\"HICP, Finland\")\n","#ax.set_ylabel(\"Index, 2015\")\n","#ax.set_xlim('2022-01-01', '2022-12-01')\n","fig.set_size_inches(12,3)"]},{"cell_type":"markdown","source":["### Forecasting for 2019"],"metadata":{"id":"NCP-IfQYoDYg"}},{"cell_type":"code","source":["train = np.array(df.loc['2000-01-01':'2016-12-01'])\n","val = np.array(df.loc['2017-01-01':'2018-12-01'])\n","\n","out = np.array(df.loc['2000-01-01':'2016-12-01']['hicp_Finland_LD'])\n","val_out = np.array(df.loc['2017-01-01':'2018-12-01']['hicp_Finland_LD'])\n","\n","out = out.reshape(len(out), 1)\n","val_out = val_out.reshape(len(val_out), 1)\n","\n","# out-of-sample inputs\n","test_set = np.array(df.loc['2018-01-01':'2018-12-01'])"],"metadata":{"id":"QoJ6SdOzoF9a","executionInfo":{"status":"aborted","timestamp":1694347327923,"user_tz":-60,"elapsed":17,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# scale\n","#scaler = preprocessing.StandardScaler()\n","#scaler.fit(train)\n","\n","#train_set = scaler.transform(train)\n","#val_set = scaler.transform(val)\n","#test_set = scaler.transform(test_set)\n","\n","train_set = np.hstack((train, out))\n","val_set = np.hstack((val, val_out))"],"metadata":{"id":"mdOKbpCQoI1S","executionInfo":{"status":"aborted","timestamp":1694347327923,"user_tz":-60,"elapsed":17,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# scale\n","#scaler = preprocessing.StandardScaler()\n","#scaler.fit(train)\n","\n","#train_set = scaler.transform(train)\n","#val_set = scaler.transform(val)\n","#test_set = scaler.transform(test_set)\n","\n","train_set = np.hstack((train, out))\n","val_set = np.hstack((val, val_out))"],"metadata":{"id":"s6TsI1zqoKRG","executionInfo":{"status":"aborted","timestamp":1694347327924,"user_tz":-60,"elapsed":17,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# timesteps\n","no_steps_in, no_steps_out = 12, 12 # use 12 data points to predict the next 12 data points\n","\n","train_X, train_y = split_sequences(train_set, no_steps_in, no_steps_out)\n","print(train_X.shape, train_y.shape)\n","val_X, val_y = split_sequences(val_set, no_steps_in, no_steps_out)\n","print(val_X.shape, val_y.shape)\n","test_set = test_set.reshape((1, no_steps_in, no_variables))\n","print(test_set.shape)"],"metadata":{"id":"mmuvLp09oL1o","executionInfo":{"status":"aborted","timestamp":1694347327924,"user_tz":-60,"elapsed":17,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = create_LSTM(no_variables, no_steps_in, no_steps_out)\n","\n","es = EarlyStopping(monitor = 'val_loss', mode = 'min', min_delta = 0.01, patience = 30, verbose = 0)\n","\n","fit = model.fit(train_X, train_y, validation_data = (val_X, val_y), epochs = 500, verbose = 0, callbacks = [es])"],"metadata":{"id":"J7EkPT71oNei","executionInfo":{"status":"aborted","timestamp":1694347327925,"user_tz":-60,"elapsed":18,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model.summary())"],"metadata":{"id":"wLRVmza1oV80","executionInfo":{"status":"aborted","timestamp":1694347327925,"user_tz":-60,"elapsed":18,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(1,1)\n","ax.plot(fit.history['loss'], color = 'blue')\n","ax.plot(fit.history['val_loss'], label = 'red', color = 'DarkRed')\n","ax.legend([\"training\", \"validation\"])\n","fig.set_size_inches(12,3)"],"metadata":{"id":"paDFvEsZoWbC","executionInfo":{"status":"aborted","timestamp":1694347327926,"user_tz":-60,"elapsed":19,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["actual = df.loc['2019-01-01':'2019-12-01']['hicp_Finland_LD']"],"metadata":{"id":"6_H_PxkDoYF_","executionInfo":{"status":"aborted","timestamp":1694347327926,"user_tz":-60,"elapsed":18,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred = model.predict(test_set, verbose = 0)\n","print(pred.shape)\n","pred = pred.reshape(pred.shape[1])\n","pred = (pd.DataFrame(pred, index=actual.index))\n","print(pred.shape)\n","print(pred)"],"metadata":{"id":"-_Od6qAtoeFj","executionInfo":{"status":"aborted","timestamp":1694347327926,"user_tz":-60,"elapsed":18,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rmse = np.sqrt(mean_squared_error(actual, pred))\n","print('Test RMSE: %.6f' % rmse)\n","\n","fig, ax = plt.subplots(1,1)\n","ax.plot(actual, color='blue')\n","ax.plot(pred, color='red')\n","ax.legend(['actual', 'predicted'])\n","ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n","ax.set_xlim(actual.index[0], actual.index[len(actual)-1])\n","fig.set_size_inches(12,3)"],"metadata":{"id":"YwZBzojRofMU","executionInfo":{"status":"aborted","timestamp":1694347327927,"user_tz":-60,"elapsed":19,"user":{"displayName":"Niklas Kuusisto","userId":"13709147410507443231"}}},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}